{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Erica', 'Hahn', 'George', 'Burke']\n"
     ]
    }
   ],
   "source": [
    "import nltk                                       #library for NLP\n",
    "from nltk.corpus import stopwords                 #library to remove stopwords\n",
    "\n",
    "#string on which we perform the analysis\n",
    "\n",
    "string = \"\"\"\n",
    "A traumatic car accident at the local market brings in multiple patients to the ER. Erica Hahn is brought in after\n",
    "George loses confidence in Burke, while his mother is embarrassing him in front of his peers. Cristina also has \n",
    "a crisis of confidence and confesses to the chief the cover-up between her and Burke.\n",
    "\"\"\"\n",
    "\n",
    "def ie_preprocess(text):\n",
    "    text = ' '.join([i for i in text.split() if i not in stopwords.words('english')]) #removing stop words\n",
    "    sentences = nltk.sent_tokenize(text)                                              #tokenizing the paragraph into sentences\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]                      #tokenize into words\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]                            #tag each word into parts of speech\n",
    "    return sentences\n",
    "\n",
    "def extract_names(text):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(text)                               #recalling the preprocessed data\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):              #grouping the data into parts of speech\n",
    "            if type(chunk) == nltk.tree.Tree:                     #forming it into a tree\n",
    "                if chunk.label() == 'PERSON':                     #recalling only the labbeled data person which is Proper noun\n",
    "                    names.append(' '.join([c[0] for c in chunk])) #appending all the results\n",
    "    return names\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = extract_names(string)                                 #calling the function\n",
    "print(names)                                                      #printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benjamin Franklin']\n"
     ]
    }
   ],
   "source": [
    "import nltk                             #library for NLP\n",
    "from nltk.corpus import stopwords       #library to remove stopwords\n",
    "\n",
    "#string on which we perform the analysis\n",
    "\n",
    "string = \"\"\"\n",
    "A couple of hundred years ago, Benjamin Franklin shared with the world the secret of his success. “Never leave that till \n",
    "tomorrow,” he said, “Which you can do today.” This is the man who discovered electricity. You’d think more of us would listen \n",
    "to what he had to say. I don’t know why we put things off, but if I had to guess, I’d say it has a lot to do with fear. Fear \n",
    "of failure. Fear of pain. Fear of rejection. Sometimes the fear is just of making a decision, because what if you’re wrong? \n",
    "What if you make a mistake you can’t undo?\n",
    "\"\"\"\n",
    "\n",
    "def ie_preprocess(text):\n",
    "    text = ' '.join([i for i in text.split() if i not in stopwords.words('english')]) #removing stop words\n",
    "    sentences = nltk.sent_tokenize(text)                                              #tokenizing the paragraph into sentences\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]                      #tokenize into words\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]                            #tag each word into parts of speech\n",
    "    return sentences\n",
    "\n",
    "def extract_names(text):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(text)                               #recalling the preprocessed data\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):              #grouping the data into parts of speech\n",
    "            if type(chunk) == nltk.tree.Tree:                     #forming it into a tree\n",
    "                if chunk.label() == 'PERSON':                     #recalling only the labbeled data person which is Proper noun\n",
    "                    names.append(' '.join([c[0] for c in chunk])) #appending all the results\n",
    "    return names\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = extract_names(string)                                 #calling the function\n",
    "print(names)                                                      #printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chandler', 'Monica', 'Joey', 'Chick Jr', 'Duck Jr Phoebe', 'Ross']\n"
     ]
    }
   ],
   "source": [
    "import nltk                                               #library for NLP\n",
    "from nltk.corpus import stopwords                         #library to remove stopwords\n",
    "\n",
    "#string on which we perform the analysis\n",
    "\n",
    "string = \"\"\"\n",
    "So, after 10 years, it comes down to this. Chandler and Monica are at the hospital waiting for the birth of their baby on the \n",
    "day before they move to their new house in the suburbs. But they might just have a surprise waiting for them in the delivery \n",
    "room. Meanwhile, Joey has a housewarming present for them, Chick Jr. and  Duck Jr Phoebe wants to turn the day into a musical. \n",
    "But the finale wouldn't be complete without another chapter in the Ross/Rachel soap opera we've been following for 10 years. \n",
    "Rachel's leaving for Paris, and Ross needs to decide if he wants to try to stop her by telling her how he feels. And with this \n",
    "gang of six involved, you can be sure there will be plenty of laughs.\n",
    "\"\"\"\n",
    "\n",
    "def ie_preprocess(text):\n",
    "    text = ' '.join([i for i in text.split() if i not in stopwords.words('english')]) #removing stop words\n",
    "    sentences = nltk.sent_tokenize(text)                                              #tokenizing the paragraph into sentences\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]                      #tokenize into words\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]                            #tag each word into parts of speech\n",
    "    return sentences\n",
    "\n",
    "def extract_names(text):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(text)                               #recalling the preprocessed data\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):              #grouping the data into parts of speech\n",
    "            if type(chunk) == nltk.tree.Tree:                     #forming it into a tree\n",
    "                if chunk.label() == 'PERSON':                     #recalling only the labbeled data person which is Proper noun\n",
    "                    names.append(' '.join([c[0] for c in chunk])) #appending all the results\n",
    "    return names\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = extract_names(string)                                 #calling the function\n",
    "print(names)                                                      #printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
